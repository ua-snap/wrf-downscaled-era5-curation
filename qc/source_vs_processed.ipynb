{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfd0362-b6f0-4046-bfe8-333c4cf253a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer, CRS, Proj, Geod\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "SELECTED_LOCATION = \"Cordova\"\n",
    "YEAR = 1991 # picked to avoid any leap year stuff possibly confounding the analysis\n",
    "SOURCE_DIR = Path(f\"/beegfs/CMIP6/wrf_era5/04km/{YEAR}\")\n",
    "\n",
    "### change this to where your outputs are\n",
    "PROCESSED_FILE = Path(f\"/beegfs/CMIP6/cparr4/daily_downscaled_era5_for_rasdaman/t2_mean/t2_mean_{YEAR}_daily_era5_4km_3338.nc\")\n",
    "source_files = sorted(SOURCE_DIR.glob(f\"era5_wrf_dscale_4km_{YEAR}-*.nc\"))\n",
    "ds_processed = xr.open_dataset(PROCESSED_FILE)\n",
    "\n",
    "# ak geographic locations, not honed to any particular dataset\n",
    "ak_locations = {\n",
    "    \"Anchorage\": (61.2181, -149.9003),\n",
    "    \"Fairbanks\": (64.8378, -147.7164),\n",
    "    \"Utqiaġvik\": (71.2906, -156.7886),\n",
    "    \"Bethel\": (60.7922, -161.7558),\n",
    "    \"Cordova\": (60.5438, -145.7573),\n",
    "    \"Nome\": (64.5011, -165.4064),\n",
    "    \"Seward\": (60.1044, -149.4458),\n",
    "    \"WRF\": (64.0, -152.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a761b-352f-497f-bbfa-2818dfe0ae4c",
   "metadata": {},
   "source": [
    "We're going to compare point extractions across a few different methods.\n",
    "We will do a \"naive\" extraction of the source WRF data using the `ak_locations` \"community\" lat-lons via finding the \"nearest\" corresponding \"XLAT\" and \"XLON\" cell.\n",
    "We will convert those to same community lat-lons to 3338 and then extract data from the processed reprojected dataset.\n",
    "But, we will also find the \"exact\" lat-lon of the **center** of the \"nearest\" grid cell that we initally found, convert those coordinates to 3338 as well and again extract from the processed reprojected dataset.\n",
    "\n",
    "When we extract data, we will also extract data from the surrounding neighborhood of pixels (up to 1 row and 1 column away) because we know that in some cases the grid cell in the source dataset that matches the values\n",
    "in the processed dataset may be offset when we don't use the \"exact\" lat-lon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588b8531-33f0-402e-95df-95b4383425a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_locations(locations_lat_lon):\n",
    "    \"\"\"Project lat/lon coordinates to EPSG:3338.\"\"\"\n",
    "    to_ak_albers = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3338\", always_xy=True)\n",
    "    projected_locs = {name: to_ak_albers.transform(lon, lat) for name, (lat, lon) in locations_lat_lon.items()}\n",
    "    return projected_locs\n",
    "\n",
    "\n",
    "def find_nearest_grid_indices(ds, locations):\n",
    "    \"\"\"Find the nearest grid indices for a set of lat/lon locations.\"\"\"\n",
    "    ak_grid_indices = {}\n",
    "    lats = ds['XLAT'].values\n",
    "    lons = ds['XLONG'].values\n",
    "    for name, (lat, lon) in locations.items():\n",
    "        # Compute squared distance for all grid points\n",
    "        dist2 = (lats - lat)**2 + (lons - lon)**2\n",
    "        idx = np.unravel_index(np.argmin(dist2), lats.shape)\n",
    "        ak_grid_indices[name] = {'south_north': idx[0], 'west_east': idx[1]}\n",
    "    return ak_grid_indices\n",
    "\n",
    "\n",
    "def find_exact_lat_lon_for_grid_cell(location_indices, sample_ds):\n",
    "    exact_locations = {}\n",
    "    for location_name, indices in location_indices.items():\n",
    "        exact_lat = float(sample_ds['XLAT'].isel(south_north=indices['south_north'],\n",
    "                                                 west_east=indices['west_east']))\n",
    "        exact_lon = float(sample_ds['XLONG'].isel(south_north=indices['south_north'],\n",
    "                                                  west_east=indices['west_east']))\n",
    "        exact_locations[location_name] = (exact_lat, exact_lon)\n",
    "        \n",
    "    return exact_locations\n",
    "\n",
    "\n",
    "def distance_km_3338(p1, p2):\n",
    "    \"\"\"Euclidean distance between two EPSG:3338 points, in metres.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p1, p2\n",
    "        Two-element sequences of *(x, y)* in metres (Alaska Albers).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Distance in metres.\n",
    "    \"\"\"\n",
    "    from math import hypot\n",
    "    dx = p2[0] - p1[0]\n",
    "    dy = p2[1] - p1[1]\n",
    "    distance_km = hypot(dx, dy) / 1000\n",
    "    return round(distance_km, 3)\n",
    "\n",
    "\n",
    "def wrf_sphere_geo_distance_km(p1, p2):\n",
    "    \"\"\"\n",
    "    Great-circle distance on WRF’s spherical Earth (km).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p1, p2\n",
    "        lat, lon in decimal degrees.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Distance in kilometres on the 6370 km-radius sphere.\n",
    "    \"\"\"\n",
    "    # radius = 6,370,000 m, flattening = 0 (a sphere)\n",
    "    _WRF_GEOD = Geod(a=6_370_000, f=0)\n",
    "    lat1, lon1 = p1\n",
    "    lat2, lon2 = p2\n",
    "    _, _, dist_m = _WRF_GEOD.inv(lon1, lat1, lon2, lat2)  # Geod wants lon/lat order\n",
    "    wrf_dist = dist_m / 1000\n",
    "    return round(wrf_dist, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a65661-4398-492b-96eb-02465a138488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community_lat</th>\n",
       "      <th>community_lon</th>\n",
       "      <th>community_m_x_3338</th>\n",
       "      <th>community_m_y_3338</th>\n",
       "      <th>south_north</th>\n",
       "      <th>west_east</th>\n",
       "      <th>exact_lat</th>\n",
       "      <th>exact_lon</th>\n",
       "      <th>exact_m_x_3338</th>\n",
       "      <th>exact_m_y_3338</th>\n",
       "      <th>community_distance_to_exact_km</th>\n",
       "      <th>community_wrf_distance_to_exact_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anchorage</th>\n",
       "      <td>61.2181</td>\n",
       "      <td>-149.9003</td>\n",
       "      <td>219349.579220</td>\n",
       "      <td>1.255302e+06</td>\n",
       "      <td>150</td>\n",
       "      <td>241</td>\n",
       "      <td>61.218018</td>\n",
       "      <td>-149.915176</td>\n",
       "      <td>218555.208050</td>\n",
       "      <td>1.255243e+06</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairbanks</th>\n",
       "      <td>64.8378</td>\n",
       "      <td>-147.7164</td>\n",
       "      <td>297698.805680</td>\n",
       "      <td>1.667062e+06</td>\n",
       "      <td>252</td>\n",
       "      <td>263</td>\n",
       "      <td>64.824120</td>\n",
       "      <td>-147.734268</td>\n",
       "      <td>296998.510903</td>\n",
       "      <td>1.665463e+06</td>\n",
       "      <td>1.746</td>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utqiaġvik</th>\n",
       "      <td>71.2906</td>\n",
       "      <td>-156.7886</td>\n",
       "      <td>-102347.938497</td>\n",
       "      <td>2.368028e+06</td>\n",
       "      <td>429</td>\n",
       "      <td>171</td>\n",
       "      <td>71.291115</td>\n",
       "      <td>-156.810669</td>\n",
       "      <td>-103155.066138</td>\n",
       "      <td>2.368118e+06</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bethel</th>\n",
       "      <td>60.7922</td>\n",
       "      <td>-161.7558</td>\n",
       "      <td>-419835.813796</td>\n",
       "      <td>1.225436e+06</td>\n",
       "      <td>149</td>\n",
       "      <td>79</td>\n",
       "      <td>60.794342</td>\n",
       "      <td>-161.776520</td>\n",
       "      <td>-420924.299218</td>\n",
       "      <td>1.225805e+06</td>\n",
       "      <td>1.149</td>\n",
       "      <td>1.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cordova</th>\n",
       "      <td>60.5438</td>\n",
       "      <td>-145.7573</td>\n",
       "      <td>449500.612970</td>\n",
       "      <td>1.201042e+06</td>\n",
       "      <td>135</td>\n",
       "      <td>299</td>\n",
       "      <td>60.537258</td>\n",
       "      <td>-145.773895</td>\n",
       "      <td>448690.657345</td>\n",
       "      <td>1.200203e+06</td>\n",
       "      <td>1.166</td>\n",
       "      <td>1.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nome</th>\n",
       "      <td>64.5011</td>\n",
       "      <td>-165.4064</td>\n",
       "      <td>-544971.699063</td>\n",
       "      <td>1.662325e+06</td>\n",
       "      <td>260</td>\n",
       "      <td>54</td>\n",
       "      <td>64.506271</td>\n",
       "      <td>-165.421295</td>\n",
       "      <td>-545577.585685</td>\n",
       "      <td>1.663016e+06</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seward</th>\n",
       "      <td>60.1044</td>\n",
       "      <td>-149.4458</td>\n",
       "      <td>252166.098298</td>\n",
       "      <td>1.132617e+06</td>\n",
       "      <td>119</td>\n",
       "      <td>249</td>\n",
       "      <td>60.107948</td>\n",
       "      <td>-149.427734</td>\n",
       "      <td>253137.514651</td>\n",
       "      <td>1.133081e+06</td>\n",
       "      <td>1.077</td>\n",
       "      <td>1.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRF</th>\n",
       "      <td>64.0000</td>\n",
       "      <td>-152.0000</td>\n",
       "      <td>97696.463114</td>\n",
       "      <td>1.560950e+06</td>\n",
       "      <td>227</td>\n",
       "      <td>213</td>\n",
       "      <td>63.990608</td>\n",
       "      <td>-151.981476</td>\n",
       "      <td>98632.925588</td>\n",
       "      <td>1.559929e+06</td>\n",
       "      <td>1.385</td>\n",
       "      <td>1.380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           community_lat  community_lon  community_m_x_3338  \\\n",
       "Anchorage        61.2181      -149.9003       219349.579220   \n",
       "Fairbanks        64.8378      -147.7164       297698.805680   \n",
       "Utqiaġvik        71.2906      -156.7886      -102347.938497   \n",
       "Bethel           60.7922      -161.7558      -419835.813796   \n",
       "Cordova          60.5438      -145.7573       449500.612970   \n",
       "Nome             64.5011      -165.4064      -544971.699063   \n",
       "Seward           60.1044      -149.4458       252166.098298   \n",
       "WRF              64.0000      -152.0000        97696.463114   \n",
       "\n",
       "           community_m_y_3338  south_north  west_east  exact_lat   exact_lon  \\\n",
       "Anchorage        1.255302e+06          150        241  61.218018 -149.915176   \n",
       "Fairbanks        1.667062e+06          252        263  64.824120 -147.734268   \n",
       "Utqiaġvik        2.368028e+06          429        171  71.291115 -156.810669   \n",
       "Bethel           1.225436e+06          149         79  60.794342 -161.776520   \n",
       "Cordova          1.201042e+06          135        299  60.537258 -145.773895   \n",
       "Nome             1.662325e+06          260         54  64.506271 -165.421295   \n",
       "Seward           1.132617e+06          119        249  60.107948 -149.427734   \n",
       "WRF              1.560950e+06          227        213  63.990608 -151.981476   \n",
       "\n",
       "           exact_m_x_3338  exact_m_y_3338  community_distance_to_exact_km  \\\n",
       "Anchorage   218555.208050    1.255243e+06                           0.797   \n",
       "Fairbanks   296998.510903    1.665463e+06                           1.746   \n",
       "Utqiaġvik  -103155.066138    2.368118e+06                           0.812   \n",
       "Bethel     -420924.299218    1.225805e+06                           1.149   \n",
       "Cordova     448690.657345    1.200203e+06                           1.166   \n",
       "Nome       -545577.585685    1.663016e+06                           0.919   \n",
       "Seward      253137.514651    1.133081e+06                           1.077   \n",
       "WRF          98632.925588    1.559929e+06                           1.385   \n",
       "\n",
       "           community_wrf_distance_to_exact_km  \n",
       "Anchorage                               0.796  \n",
       "Fairbanks                               1.740  \n",
       "Utqiaġvik                               0.789  \n",
       "Bethel                                  1.149  \n",
       "Cordova                                 1.163  \n",
       "Nome                                    0.916  \n",
       "Seward                                  1.076  \n",
       "WRF                                     1.380  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak_locations_3338 = project_locations(ak_locations)\n",
    "with xr.open_dataset(source_files[0]) as sample_ds:\n",
    "    grid_indices = find_nearest_grid_indices(sample_ds, ak_locations)\n",
    "    exact_lat_lons = find_exact_lat_lon_for_grid_cell(grid_indices, sample_ds)\n",
    "ak_exact_locations_3338 = project_locations(exact_lat_lons)\n",
    "\n",
    "ak_locations_df = pd.DataFrame.from_dict(ak_locations, orient=\"index\", columns=[\"community_lat\", \"community_lon\"])\n",
    "ak_grid_indices_df = pd.DataFrame.from_dict(grid_indices, orient=\"index\", columns=[\"south_north\", \"west_east\"])\n",
    "ak_exact_locations_df = pd.DataFrame.from_dict(exact_lat_lons, orient=\"index\", columns=[\"exact_lat\", \"exact_lon\"])\n",
    "ak_locations_3338_df = pd.DataFrame.from_dict(ak_locations_3338, orient=\"index\", columns=[\"community_m_x_3338\", \"community_m_y_3338\"])\n",
    "ak_exact_locations_3338_df = pd.DataFrame.from_dict(ak_exact_locations_3338, orient=\"index\", columns=[\"exact_m_x_3338\", \"exact_m_y_3338\"])\n",
    "ak_extraction_df = pd.concat([ak_locations_df, ak_locations_3338_df, ak_grid_indices_df, ak_exact_locations_df, ak_exact_locations_3338_df], axis=1)\n",
    "\n",
    "ak_extraction_df[\"community_distance_to_exact_km\"] = (\n",
    "    ak_extraction_df\n",
    "    .apply(\n",
    "        lambda row: distance_km_3338(\n",
    "            (row[\"community_m_x_3338\"], row[\"community_m_y_3338\"]),\n",
    "            (row[\"exact_m_x_3338\"],     row[\"exact_m_y_3338\"])\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "ak_extraction_df[\"community_wrf_distance_to_exact_km\"] = (\n",
    "    ak_extraction_df\n",
    "        .apply(\n",
    "            lambda row: wrf_sphere_geo_distance_km(\n",
    "                (row[\"community_lat\"], row[\"community_lon\"]),\n",
    "                (row[\"exact_lat\"],     row[\"exact_lon\"])\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    ")\n",
    "ak_extraction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53398c2b-be2f-4f29-9a09-11af4d8e5931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Anchorage...\n",
      "Processing 365 source files in a loop for multiple offsets...\n",
      "Combining daily means for each offset...\n",
      "Extracting data from processed file using the COMMUNITY x and y...\n",
      "Extracting data from processed file using the EXACT x and y...\n",
      "Processing Fairbanks...\n",
      "Processing 365 source files in a loop for multiple offsets...\n",
      "Combining daily means for each offset...\n",
      "Extracting data from processed file using the COMMUNITY x and y...\n",
      "Extracting data from processed file using the EXACT x and y...\n",
      "Processing Utqiaġvik...\n",
      "Processing 365 source files in a loop for multiple offsets...\n",
      "Combining daily means for each offset...\n",
      "Extracting data from processed file using the COMMUNITY x and y...\n",
      "Extracting data from processed file using the EXACT x and y...\n",
      "Processing Bethel...\n",
      "Processing 365 source files in a loop for multiple offsets...\n",
      "Combining daily means for each offset...\n",
      "Extracting data from processed file using the COMMUNITY x and y...\n",
      "Extracting data from processed file using the EXACT x and y...\n",
      "Processing Cordova...\n",
      "Processing 365 source files in a loop for multiple offsets...\n",
      "Combining daily means for each offset...\n",
      "Extracting data from processed file using the COMMUNITY x and y...\n",
      "Extracting data from processed file using the EXACT x and y...\n",
      "Processing Nome...\n",
      "Processing 365 source files in a loop for multiple offsets...\n",
      "Combining daily means for each offset...\n",
      "Extracting data from processed file using the COMMUNITY x and y...\n",
      "Extracting data from processed file using the EXACT x and y...\n",
      "Processing Seward...\n",
      "Processing 365 source files in a loop for multiple offsets...\n",
      "Combining daily means for each offset...\n",
      "Extracting data from processed file using the COMMUNITY x and y...\n",
      "Extracting data from processed file using the EXACT x and y...\n",
      "Processing WRF...\n",
      "Processing 365 source files in a loop for multiple offsets...\n",
      "Combining daily means for each offset...\n",
      "Extracting data from processed file using the COMMUNITY x and y...\n",
      "Extracting data from processed file using the EXACT x and y...\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for location in ak_locations:\n",
    "    print(f\"Processing {location}...\")\n",
    "    results[location] = {}\n",
    "    # search the neighborhood around the grid cell\n",
    "    daily_means_dict = { (di,dj): [] for di in [-1,0,1] for dj in [-1,0,1] }\n",
    "    print(f\"Processing {len(source_files)} source files in a loop for multiple offsets...\")\n",
    "    for f in source_files:\n",
    "        # could use mf data open here, but this is fast enough\n",
    "        with xr.open_dataset(f) as ds:\n",
    "            for di,dj in daily_means_dict.keys():\n",
    "                \n",
    "                wn = grid_indices[location]['west_east'] + di\n",
    "                sn = grid_indices[location]['south_north'] + dj\n",
    "                \n",
    "                wn = max(0, min(wn, ds.dims['west_east']-1))\n",
    "                sn = max(0, min(sn, ds.dims['south_north']-1))\n",
    "                \n",
    "                source_raw = ds['T2'].isel(west_east=wn, south_north=sn)\n",
    "                \n",
    "                daily_mean = source_raw.resample(Time=\"1D\").mean() - 273.15\n",
    "                daily_means_dict[(di,dj)].append(daily_mean)\n",
    "            \n",
    "    print(\"Combining daily means for each offset...\")\n",
    "    offset_series = {}\n",
    "    for key, lst in daily_means_dict.items():\n",
    "        series = xr.concat(lst, dim=\"Time\").rename({'Time':'time'}).rename(\"t2_mean_source\")\n",
    "        offset_series[key] = series\n",
    "\n",
    "    print(\"Extracting data from processed file using the COMMUNITY x and y...\")\n",
    "    processed_daily_mean_community = ds_processed[\"t2_mean\"].sel(\n",
    "        x=ak_locations_3338[location][0],\n",
    "        y=ak_locations_3338[location][1],\n",
    "        method=\"nearest\"\n",
    "    )\n",
    "    \n",
    "    print(\"Extracting data from processed file using the EXACT x and y...\")\n",
    "    processed_daily_mean_exact = ds_processed[\"t2_mean\"].sel(\n",
    "        x=ak_exact_locations_3338[location][0],\n",
    "        y=ak_exact_locations_3338[location][1],\n",
    "        method=\"nearest\"\n",
    "    )\n",
    "\n",
    "    # find the best ofset for the initial COMMUNITY coordinates\n",
    "    community_delta_dict = {}\n",
    "    for key, src_series in offset_series.items():\n",
    "        aligned_src, aligned_proc = xr.align(src_series, processed_daily_mean_community, join=\"inner\")\n",
    "        d = aligned_proc - aligned_src\n",
    "        community_delta_dict[key] = float(np.abs(d).mean())\n",
    "    # pick best offset (minimum mean abs delta)\n",
    "    community_best_offset = min(community_delta_dict, key=community_delta_dict.get)\n",
    "    \n",
    "    # find the best ofset for the EXACT coordinates\n",
    "    exact_delta_dict = {}\n",
    "    for key, src_series in offset_series.items():\n",
    "        aligned_src, aligned_proc = xr.align(src_series, processed_daily_mean_exact, join=\"inner\")\n",
    "        d = aligned_proc - aligned_src\n",
    "        exact_delta_dict[key] = float(np.abs(d).mean())\n",
    "    # pick best offset (minimum mean abs delta)\n",
    "    exact_best_offset = min(exact_delta_dict, key=exact_delta_dict.get)\n",
    "\n",
    "    results[location][\"exact_best_offset\"] = exact_best_offset\n",
    "    results[location][\"community_best_offset\"] = community_best_offset\n",
    "\n",
    "    results[location][\"exact_mean_abs_delta_of_offset\"] = round(exact_delta_dict[exact_best_offset], 2)\n",
    "    results[location][\"community_mean_abs_delta_of_offset\"] = round(community_delta_dict[community_best_offset], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9e6987-2cf4-46b1-abf4-8f38a7bfbdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anchorage': {'exact_best_offset': (0, 0),\n",
       "  'community_best_offset': (0, 0),\n",
       "  'exact_mean_abs_delta_of_offset': 0.0,\n",
       "  'community_mean_abs_delta_of_offset': 0.0},\n",
       " 'Fairbanks': {'exact_best_offset': (0, 0),\n",
       "  'community_best_offset': (1, 1),\n",
       "  'exact_mean_abs_delta_of_offset': 0.0,\n",
       "  'community_mean_abs_delta_of_offset': 0.0},\n",
       " 'Utqiaġvik': {'exact_best_offset': (0, 0),\n",
       "  'community_best_offset': (0, 0),\n",
       "  'exact_mean_abs_delta_of_offset': 0.0,\n",
       "  'community_mean_abs_delta_of_offset': 0.0},\n",
       " 'Bethel': {'exact_best_offset': (0, 0),\n",
       "  'community_best_offset': (1, 0),\n",
       "  'exact_mean_abs_delta_of_offset': 0.0,\n",
       "  'community_mean_abs_delta_of_offset': 0.0},\n",
       " 'Cordova': {'exact_best_offset': (0, 0),\n",
       "  'community_best_offset': (0, 1),\n",
       "  'exact_mean_abs_delta_of_offset': 0.0,\n",
       "  'community_mean_abs_delta_of_offset': 0.0},\n",
       " 'Nome': {'exact_best_offset': (0, 0),\n",
       "  'community_best_offset': (0, 0),\n",
       "  'exact_mean_abs_delta_of_offset': 0.0,\n",
       "  'community_mean_abs_delta_of_offset': 0.0},\n",
       " 'Seward': {'exact_best_offset': (0, 0),\n",
       "  'community_best_offset': (0, -1),\n",
       "  'exact_mean_abs_delta_of_offset': 0.0,\n",
       "  'community_mean_abs_delta_of_offset': 0.0},\n",
       " 'WRF': {'exact_best_offset': (0, 0),\n",
       "  'community_best_offset': (0, 0),\n",
       "  'exact_mean_abs_delta_of_offset': 0.0,\n",
       "  'community_mean_abs_delta_of_offset': 0.0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b5e4b-18be-4e52-9294-0b87572af17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
